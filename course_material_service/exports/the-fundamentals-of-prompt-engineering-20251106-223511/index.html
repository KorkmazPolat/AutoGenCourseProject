<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>The Fundamentals of Prompt Engineering | Full Course</title>
    <style>
      body { font-family: Arial, sans-serif; margin: 0; padding: 24px; background: #eef2f7; color: #1f2933; }
      main { max-width: 980px; margin: 0 auto; background: #ffffff; padding: 24px; border: 1px solid #d2d6dc; }
      h1, h2, h3, h4 { margin-top: 24px; }
      h1 { margin-top: 0; }
      ul, ol { padding-left: 20px; }
      .module { border: 1px solid #d2d6dc; padding: 16px; margin-bottom: 24px; background: #f8fafc; }
      .muted { color: #52606d; font-size: 0.9rem; }
      a.back { text-decoration: none; color: #2563eb; }
      video { width: 100%; height: auto; margin-top: 12px; background: #000; }
      .asset-block { margin-top: 16px; }
      table { width: 100%; border-collapse: collapse; margin-top: 12px; }
      table th, table td { border: 1px solid #d2d6dc; padding: 8px; text-align: left; }
      .meta { margin: 8px 0; }
      /* Quiz styles */
      .quiz-form { margin-top: 8px; }
      .choice-list { list-style: none; padding-left: 0; }
      .choice-list li { margin: 4px 0; }
      .question { padding: 8px; border-left: 4px solid transparent; }
      .question.correct { background: #f0fdf4; border-left-color: #22c55e; }
      .question.incorrect { background: #fef2f2; border-left-color: #ef4444; }
      .badge { display: inline-block; padding: 2px 6px; font-size: 0.8rem; border-radius: 999px; margin-left: 6px; }
      .badge.correct { background: #dcfce7; color: #166534; }
      .badge.incorrect { background: #fee2e2; color: #991b1b; }
      .quiz-actions { margin-top: 10px; }
      .quiz-actions button { padding: 8px 12px; background: #2563eb; color: #fff; border: none; cursor: pointer; }
      .quiz-result { margin-top: 10px; font-family: system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif; }
      .quiz-result .stats { font-weight: bold; }
      .quiz-result .wrong-list { margin-top: 6px; }
    </style>
  </head>
  <body>
    <main>
      <a class="back" href="/">&larr; back</a>
      <h1>The Fundamentals of Prompt Engineering</h1>
      <p class="muted">Full course build: blueprint, per-module videos, readings, and quizzes.</p>

      
      <h2>Course outcomes</h2>
      <ul>
        
        <li>Explain the difference between zero-shot, few-shot, and chain-of-thought prompting.</li>
        
        <li>Apply iterative prompt refinement to achieve specific outcomes.</li>
        
        <li>Identify and mitigate common prompt failures like hallucination and ambiguity.</li>
        
      </ul>
      

      
      <h2>Blueprint overview</h2>
      
      <p><strong>Positioning:</strong> Introduction to the core concepts of prompt engineering, designed to empower beginners in data science and software development.</p>
      <p class="meta"><strong>Audience:</strong> Beginner Data Scientists and Software Developers</p>
      <p class="meta"><strong>Total duration:</strong> 0.2</p>
      <p class="meta"><strong>Pacing:</strong> Self-paced learning with short, focused modules</p>
      
      
      

      
      
      
      
      
      
      
      
      
      
      
      <div class="module">
        <h2>Module 1: Understanding Prompting Techniques</h2>
        <p>An introduction to the various prompting techniques and their applications in AI models.</p>
        <p><strong>Module outcomes:</strong> Explain the difference between zero-shot, few-shot, and chain-of-thought prompting.</p>
        <p><strong>Key topics:</strong> Zero-shot prompting, Few-shot prompting, Chain-of-thought prompting</p>

        
        <div class="asset-block">
          <h3>Lesson Video</h3>
          <video controls preload="metadata">
            <source src="videos/the_fundamentals_of_prompt_engineering_module_1_understanding_prompting_techniques_20251106192734.mp4" type="video/mp4" />
            
            <track kind="subtitles" src="videos/the_fundamentals_of_prompt_engineering_module_1_understanding_prompting_techniques_20251106192734.vtt" srclang="en" label="English" default />
            
            
            <track kind="chapters" src="videos/the_fundamentals_of_prompt_engineering_module_1_understanding_prompting_techniques_20251106192734.chapters.vtt" srclang="en" label="Chapters" />
            
            Your browser does not support the video tag.
          </video>
          <p class="muted">Narration voice: alloy</p>
        </div>
        

        
        <div class="asset-block">
          <h3>Video script</h3>
          <p><strong>Hook:</strong> Unlock AI potential with powerful prompting techniques!</p>
          
          <h4>Outline</h4>
          <ul>
            
            <li>00:00 — Introduction to Prompting</li>
            
            <li>01:00 — What is Zero-shot Prompting?</li>
            
            <li>02:30 — Applications of Zero-shot Prompting</li>
            
            <li>04:00 — Understanding Few-shot Prompting</li>
            
            <li>05:30 — Few-shot Prompting Examples</li>
            
            <li>07:00 — Chain-of-thought Prompting Explained</li>
            
            <li>08:30 — Benefits of Chain-of-thought Prompting</li>
            
            <li>10:00 — Comparing Prompting Techniques</li>
            
            <li>11:00 — Best Practices for Prompting</li>
            
            <li>11:30 — Summary of Key Techniques</li>
            
            <li>12:00 — Call to Action</li>
            
          </ul>
          
          
          <h4>Narration</h4>
          <ul>
            
            <li>
              <strong>Introduction to Prompting</strong>: Introduce the concept of prompting in AI.<br />
              Welcome to the world of prompt engineering! Today, we’re diving into the fundamental techniques that can enhance AI interactions. By the end of this lesson, you’ll grasp key prompting strategies that can significantly influence how AI models generate responses. Let’s explore how simple adjustments can yield powerful results. Are you ready?
            </li>
            
            <li>
              <strong>What is Zero-shot Prompting?</strong>: Define zero-shot prompting and its significance.<br />
              Zero-shot prompting involves providing a task to a model without any examples. This method is powerful, as it requires the model to understand the request based solely on its existing knowledge. For instance, asking an AI to summarize a text it has never encountered is a prime example. How does this differ from other techniques? It&#39;s all about immediate capability!
            </li>
            
            <li>
              <strong>Applications of Zero-shot Prompting</strong>: Explore real-world uses of zero-shot prompting.<br />
              Zero-shot prompting shines in numerous applications. For example, in natural language processing, it&#39;s used in classification tasks where no labeled examples are needed. Research shows that using zero-shot techniques can lead to accuracy levels over 70% in certain classifications, bringing efficiency to AI development. Can you imagine the possibilities across various industries, from customer service to content creation?
            </li>
            
            <li>
              <strong>Understanding Few-shot Prompting</strong>: Introduce and illustrate few-shot prompting.<br />
              Next, we have few-shot prompting. This technique provides the model with a handful of examples to learn from. Essentially, you give it a few scenarios, allowing the AI to identify patterns and make better predictions. For instance, supplying just three examples of a specific query lets the model generalize its approach effectively. Isn’t it fascinating how minimal data can drive high performance?
            </li>
            
            <li>
              <strong>Few-shot Prompting Examples</strong>: Demonstrate few-shot prompting with concrete cases.<br />
              Consider a situation where you input three different text summaries as examples. The model adapts its generated summaries based on these cues, often achieving up to 80% accuracy in replicating your intent. This method is particularly valuable in domains like personalized recommendations and automated responses. How could you implement this technique in your own projects?
            </li>
            
            <li>
              <strong>Benefits of Chain-of-thought Prompting</strong>: Highlight the advantages of chain-of-thought prompting in AI.<br />
              By employing chain-of-thought prompting, models see improved accuracy and logical consistency. Studies indicate an increase in problem-solving abilities by nearly 15% when this approach is utilized. It’s also beneficial in educational tech, where AI tutors can walk students through concepts step-by-step. What if you could make learning more engaging using this technique?
            </li>
            
            <li>
              <strong>Comparing Prompting Techniques</strong>: Compare and contrast the different prompting techniques.<br />
              Now, let&#39;s compare the three techniques we&#39;ve discussed. Zero-shot prompting is great for immediate tasks without prior data, few-shot prompting enhances understanding with minimal examples, and chain-of-thought prompting leverages logical reasoning. Each has its unique strengths, and understanding when to use each can make a big difference in your AI applications. Which technique do you think would be most beneficial for your projects?
            </li>
            
            <li>
              <strong>Best Practices for Prompting</strong>: Offer essential tips for effective prompting.<br />
              To conclude our lesson, let&#39;s cover some best practices for prompting. Keep prompts clear and concise, encourage exploration with varied examples, and always experiment with different techniques. It’s important to iterate based on results. Regular feedback cycles will optimize your prompting strategy. What steps will you take immediately to improve your prompting?
            </li>
            
            <li>
              <strong>Summary of Key Techniques</strong>: Recap the prompting techniques learned.<br />
              To summarize, we’ve explored zero-shot, few-shot, and chain-of-thought prompting. Each technique has its own use cases and benefits, playing vital roles in AI development. The key takeaway? Choose the right prompting strategy based on your project needs and user expectations. Ready to dive deeper into an AI application?
            </li>
            
            <li>
              <strong>Call to Action</strong>: Encourage further learning and exploration of techniques.<br />
              Thank you for joining this introductory lesson on prompting techniques! I encourage you to practice these methods in your own projects. Engage with the content, and don’t hesitate to ask questions or share your experiences with prompting. Discover the full potential of AI by mastering these strategies!
            </li>
            
          </ul>
          
          <p><strong>Recap:</strong> We&#39;ve covered prompt engineering, focusing on zero-shot, few-shot, and chain-of-thought prompting techniques. Understanding these methods sharpens your skills in AI interactions.</p>
          <p><strong>Call to action:</strong> Dive deeper into practical applications and start implementing these techniques today!</p>
        </div>
        

        
        <div class="asset-block">
          <h3>Reading companion</h3>
          <p><strong>Summary:</strong> This handout introduces various prompting techniques in AI, focusing on zero-shot, few-shot, and chain-of-thought prompting.</p>
          
          <h4>Sections</h4>
          <ul>
            
            <li>
              <strong>Zero-Shot Prompting</strong>
              
              <ul>
                
                <li>Definition</li>
                
                <li>Use Cases</li>
                
                <li>Advantages and Disadvantages</li>
                
              </ul>
              
              <p>Zero-shot prompting refers to providing a prompt to an AI model without any examples to guide its response. It relies completely on the model&#39;s pre-existing knowledge to generate an answer.</p>
              
              <p class="muted">Outcomes: Explain the difference between zero-shot, few-shot, and chain-of-thought prompting.</p>
              
            </li>
            
            <li>
              <strong>Few-Shot Prompting</strong>
              
              <ul>
                
                <li>Definition</li>
                
                <li>Examples</li>
                
                <li>Effectiveness</li>
                
              </ul>
              
              <p>Few-shot prompting involves providing a few examples within the prompt to help the AI model generate a better response. This technique can enhance the model&#39;s performance by giving it a clearer context.</p>
              
              <p class="muted">Outcomes: Explain the difference between zero-shot, few-shot, and chain-of-thought prompting.</p>
              
            </li>
            
            <li>
              <strong>Chain-of-Thought Prompting</strong>
              
              <ul>
                
                <li>Definition</li>
                
                <li>Step-by-Step Reasoning</li>
                
                <li>Application in Complex Tasks</li>
                
              </ul>
              
              <p>Chain-of-thought prompting encourages the AI model to generate reasoning steps in its response. This method can improve accuracy in tasks requiring multiple logical steps.</p>
              
              <p class="muted">Outcomes: Explain the difference between zero-shot, few-shot, and chain-of-thought prompting.</p>
              
            </li>
            
          </ul>
          
          
          <h4>Examples</h4>
          <ul>
            
            <li>
              <strong>Zero-Shot Prompting Example</strong> — Asking an AI model to summarize a text without providing context or examples of summaries.
              
              <span class="muted">(Outcomes: Explain the difference between zero-shot, few-shot, and chain-of-thought prompting.)</span>
              
            </li>
            
            <li>
              <strong>Few-Shot Prompting Example</strong> — Providing two examples of customer inquiries followed by a new inquiry for the AI to respond to, enhancing understanding.
              
              <span class="muted">(Outcomes: Explain the difference between zero-shot, few-shot, and chain-of-thought prompting.)</span>
              
            </li>
            
            <li>
              <strong>Chain-of-Thought Prompting Example</strong> — Requesting the AI to solve a math problem while showing each step in the calculation process.
              
              <span class="muted">(Outcomes: Explain the difference between zero-shot, few-shot, and chain-of-thought prompting.)</span>
              
            </li>
            
          </ul>
          
          
          <h4>Glossary</h4>
          <ul>
            
            <li><strong>Zero-Shot Prompting</strong>: A prompting technique where the AI is given a task without any examples to inform its response.</li>
            
            <li><strong>Few-Shot Prompting</strong>: A prompting approach that involves providing several examples to guide the AI&#39;s output.</li>
            
            <li><strong>Chain-of-Thought Prompting</strong>: A technique that prompts the AI to include a sequence of reasoning steps to derive a conclusion.</li>
            
          </ul>
          
          
          <h4>Reflection prompts</h4>
          <ul>
            
            <li>Understanding these prompting techniques is crucial for effectively leveraging AI models in real-world applications.</li>
            
            <li>Experimenting with different prompting methods can lead to improved results in AI-generated outputs.</li>
            
          </ul>
          
        </div>
        

        
        <div class="asset-block">
          <h3>Quiz</h3>
          
          <form class="quiz-form" id="quiz-form-1">
            <ol>
              
              
              <li class="question" data-answer="A" data-stem="What is the primary characteristic of zero-shot prompting?">
                <div>
                  <strong>What is the primary characteristic of zero-shot prompting?</strong>
                  <span class="badge" aria-live="polite"></span>
                </div>
                <ul class="choice-list">
                  
                  <li>
                    <label>
                      <input type="radio" name="q0-m1" value="A" />
                      A. It provides no examples and relies solely on the model&#39;s pre-trained knowledge.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q0-m1" value="B" />
                      B. It includes several examples to guide the model&#39;s responses.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q0-m1" value="C" />
                      C. It involves a step-by-step breakdown of tasks.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q0-m1" value="D" />
                      D. It uses feedback loops to refine outputs.
                    </label>
                  </li>
                  
                </ul>
                
                <p class="muted">Outcome: Explain the difference between zero-shot, few-shot, and chain-of-thought prompting.</p>
                
                
                <p class="muted rationale" style="display:none;">Rationale: Zero-shot prompting does not provide any examples or specific guidance, relying only on the model&#39;s existing knowledge base for response generation.</p>
                
              </li>
              
              
              <li class="question" data-answer="B" data-stem="In which scenario would few-shot prompting be most appropriately applied?">
                <div>
                  <strong>In which scenario would few-shot prompting be most appropriately applied?</strong>
                  <span class="badge" aria-live="polite"></span>
                </div>
                <ul class="choice-list">
                  
                  <li>
                    <label>
                      <input type="radio" name="q1-m1" value="A" />
                      A. When there are no constraints placed on the model&#39;s responses.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q1-m1" value="B" />
                      B. When you want to guide the model using a couple of concrete examples.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q1-m1" value="C" />
                      C. When you need a detailed breakdown of reasoning steps.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q1-m1" value="D" />
                      D. When immediate feedback is necessary to refine the response.
                    </label>
                  </li>
                  
                </ul>
                
                <p class="muted">Outcome: Explain the difference between zero-shot, few-shot, and chain-of-thought prompting.</p>
                
                
                <p class="muted rationale" style="display:none;">Rationale: Few-shot prompting is utilized when there are a limited number of examples given to help inform the model&#39;s responses, allowing it to generalize from these examples.</p>
                
              </li>
              
              
              <li class="question" data-answer="B" data-stem="Why is chain-of-thought prompting beneficial when working with complex questions?">
                <div>
                  <strong>Why is chain-of-thought prompting beneficial when working with complex questions?</strong>
                  <span class="badge" aria-live="polite"></span>
                </div>
                <ul class="choice-list">
                  
                  <li>
                    <label>
                      <input type="radio" name="q2-m1" value="A" />
                      A. It operates with no examples, ensuring only the final answer is displayed.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q2-m1" value="B" />
                      B. It breaks down problems into smaller steps, aiding in logical reasoning.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q2-m1" value="C" />
                      C. It only provides the model&#39;s first impression without elaborating.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q2-m1" value="D" />
                      D. It relies solely on user input without providing any feedback.
                    </label>
                  </li>
                  
                </ul>
                
                <p class="muted">Outcome: Explain the difference between zero-shot, few-shot, and chain-of-thought prompting.</p>
                
                
                <p class="muted rationale" style="display:none;">Rationale: Chain-of-thought prompting encourages the model to articulate its reasoning step-by-step, which enhances comprehension and facilitates solutions to complex problems.</p>
                
              </li>
              
              
              <li class="question" data-answer="C" data-stem="Given a task that requires multiple reasoning steps, which prompting technique would yield the best results?">
                <div>
                  <strong>Given a task that requires multiple reasoning steps, which prompting technique would yield the best results?</strong>
                  <span class="badge" aria-live="polite"></span>
                </div>
                <ul class="choice-list">
                  
                  <li>
                    <label>
                      <input type="radio" name="q3-m1" value="A" />
                      A. Zero-shot prompting.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q3-m1" value="B" />
                      B. Few-shot prompting.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q3-m1" value="C" />
                      C. Chain-of-thought prompting.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q3-m1" value="D" />
                      D. Randomized prompting.
                    </label>
                  </li>
                  
                </ul>
                
                <p class="muted">Outcome: Explain the difference between zero-shot, few-shot, and chain-of-thought prompting.</p>
                
                
                <p class="muted rationale" style="display:none;">Rationale: Chain-of-thought prompting is specifically designed for tasks that require detailed reasoning, making it the best choice for complex queries that involve multiple logical steps.</p>
                
              </li>
              
              
              <li class="question" data-answer="B" data-stem="If a data scientist wanted to quickly generate responses without prior examples, which technique should they consider?">
                <div>
                  <strong>If a data scientist wanted to quickly generate responses without prior examples, which technique should they consider?</strong>
                  <span class="badge" aria-live="polite"></span>
                </div>
                <ul class="choice-list">
                  
                  <li>
                    <label>
                      <input type="radio" name="q4-m1" value="A" />
                      A. Chain-of-thought prompting.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q4-m1" value="B" />
                      B. Zero-shot prompting.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q4-m1" value="C" />
                      C. Few-shot prompting.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q4-m1" value="D" />
                      D. Sequential prompting.
                    </label>
                  </li>
                  
                </ul>
                
                <p class="muted">Outcome: Explain the difference between zero-shot, few-shot, and chain-of-thought prompting.</p>
                
                
                <p class="muted rationale" style="display:none;">Rationale: Zero-shot prompting is the appropriate choice when no prior examples are provided, allowing the model to generate outputs based solely on pre-existing knowledge.</p>
                
              </li>
              
            </ol>
            <div class="quiz-actions">
              <button type="button" class="submit-quiz" data-module="1">Check answers</button>
            </div>
            <div class="quiz-result" id="quiz-result-1" aria-live="polite"></div>
          </form>
          
          
          <p><strong>Remediation tip:</strong> For further understanding, revisit the module on prompting techniques and explore how each method can be applied in real-world scenarios.</p>
          
        </div>
        
      </div>
      
      
      
      
      
      
      
      
      
      
      <div class="module">
        <h2>Module 2: Iterative Prompt Refinement</h2>
        <p>Learn how to refine prompts iteratively to achieve desired outcomes effectively.</p>
        <p><strong>Module outcomes:</strong> Apply iterative prompt refinement to achieve specific outcomes.</p>
        <p><strong>Key topics:</strong> Iterative refinement, Testing prompts, Linking prompts to outcomes</p>

        
        <div class="asset-block">
          <h3>Lesson Video</h3>
          <video controls preload="metadata">
            <source src="videos/the_fundamentals_of_prompt_engineering_module_2_iterative_prompt_refinement_20251106193037.mp4" type="video/mp4" />
            
            <track kind="subtitles" src="videos/the_fundamentals_of_prompt_engineering_module_2_iterative_prompt_refinement_20251106193037.vtt" srclang="en" label="English" default />
            
            
            <track kind="chapters" src="videos/the_fundamentals_of_prompt_engineering_module_2_iterative_prompt_refinement_20251106193037.chapters.vtt" srclang="en" label="Chapters" />
            
            Your browser does not support the video tag.
          </video>
          <p class="muted">Narration voice: alloy</p>
        </div>
        

        
        <div class="asset-block">
          <h3>Video script</h3>
          <p><strong>Hook:</strong> Unlock the power of prompt engineering with iterative refinement!</p>
          
          <h4>Outline</h4>
          <ul>
            
            <li>00:00 — Introduction to Iterative Refinement</li>
            
            <li>01:00 — What is Iterative Refinement?</li>
            
            <li>02:00 — Importance of Testing</li>
            
            <li>03:00 — Linking Prompts to Outcomes</li>
            
            <li>04:00 — Step-by-Step Refinement Process</li>
            
            <li>05:00 — Common Testing Strategies</li>
            
            <li>06:00 — Using Feedback for Refinement</li>
            
            <li>07:00 — Real-World Application Case Study</li>
            
            <li>08:00 — Analyzing Outcomes from Refined Prompts</li>
            
            <li>09:00 — Iterative Refinement Tools</li>
            
            <li>10:00 — Best Practices for Effective Refinement</li>
            
            <li>11:00 — Conclusion and Next Steps</li>
            
          </ul>
          
          
          <h4>Narration</h4>
          <ul>
            
            <li>
              <strong>Introduction to Iterative Refinement</strong>: Introduction to the concept<br />
              In this module, we delve into the concept of iterative prompt refinement—your key to harnessing prompt engineering effectively. Imagine you have a powerful model, but without the right prompt, its potential remains untapped. Today, we will explore how refining your prompts can lead to much clearer and desired outputs. Get ready to learn techniques that will enhance your skills and outcomes significantly.
            </li>
            
            <li>
              <strong>What is Iterative Refinement?</strong>: Understanding the process<br />
              Iterative refinement refers to the ongoing process of enhancing your prompts based on previous outcomes. Instead of crafting the perfect prompt on the first try, we embrace a cycle of creating, testing, and revising prompts. This approach ensures that we continuously improve our results. Think of it as sculpting a statue—every chip away reveals a bit more of the masterpiece.
            </li>
            
            <li>
              <strong>Importance of Testing</strong>: Why testing is crucial<br />
              Testing your prompts is crucial for understanding their effectiveness. For instance, let&#39;s say you prompt a model about the weather, but the output is vague. Through testing, you will pinpoint what works and what doesn’t. Effective testing enables faster iterations and leads to better outcomes. Without this step, your refinements might be misguided.
            </li>
            
            <li>
              <strong>Linking Prompts to Outcomes</strong>: Connecting the two concepts<br />
              A well-crafted prompt should directly link to the desired outcome. Ask yourself: what do I want? By clearly defining what you aim to achieve, you can design prompts that drive towards these results. For example, if your goal is to generate sales insights, your prompt should be specific to that domain, reducing ambiguity.
            </li>
            
            <li>
              <strong>Step-by-Step Refinement Process</strong>: A structured refinement approach<br />
              Let’s break down the iterative refinement process step-by-step. Start with an initial prompt, then evaluate its performance. From there, identify areas for improvement; whether it’s clarity, specificity, or context, adjust accordingly. Repeat this cycle until the outcomes align with your expectations. This structured method maximizes your chances of achieving excellence.
            </li>
            
            <li>
              <strong>Common Testing Strategies</strong>: Exploring various strategies<br />
              When testing your prompts, there are several strategies you can use. A/B testing allows you to compare different prompts side by side, while user feedback is invaluable in gauging clarity and effectiveness. Additionally, quantitative metrics can reveal hidden insights. Remember, diverse testing strategies yield richer data for refinement.
            </li>
            
            <li>
              <strong>Using Feedback for Refinement</strong>: Applying feedback effectively<br />
              Feedback is a goldmine for prompt refinement! Collecting insights from users and stakeholders helps identify gaps in your prompts. Actively solicit opinions and iterate based on constructive criticism. Consider a case where feedback pointed out a lack of detail; by addressing this, your next prompt will likely yield more specific results.
            </li>
            
            <li>
              <strong>Real-World Application Case Study</strong>: An example in action<br />
              Let&#39;s look at a real-world application of iterative refinement. A leading e-commerce platform integrated this technique to enhance their customer support prompts. Initially vague, the prompts led to confusion. Through iterative refinement, they added context and specifics, leading to a 25% improvement in response accuracy. This demonstrates the tangible benefits of our discussed methods.
            </li>
            
            <li>
              <strong>Analyzing Outcomes from Refined Prompts</strong>: Understanding results analysis<br />
              After refining your prompts, analyzing the outcomes is key. Identify trends in the responses—are they more accurate? Are they more aligned with expectations? Consider using visualization techniques like bar charts to track performance improvements over time. Understanding these outcomes will refine your overall strategy.
            </li>
            
            <li>
              <strong>Iterative Refinement Tools</strong>: Helpful tools for the process<br />
              There are various tools available for facilitating iterative refinement as well. From prompt design tools to user feedback platforms, leveraging technology can vastly improve your efficiency. Tools like feedback forms or analytics dashboards will help streamline the process and keep your prompts sharp.
            </li>
            
            <li>
              <strong>Best Practices for Effective Refinement</strong>: Key strategies to remember<br />
              To wrap up, let&#39;s highlight best practices for effective iterative refinement. Always start with a clear goal, test thoroughly, gather diverse feedback, and document your iterations. Lastly, embrace adaptability; flexibility in your approach is vital in navigating the complexities of prompt engineering.
            </li>
            
            <li>
              <strong>Conclusion and Next Steps</strong>: Summarizing key takeaways<br />
              As we conclude this module, remember that iterative prompt refinement is an ongoing journey. Embrace the iterative process, employ tested strategies, and refine your prompts continually. We’re excited for you to apply these concepts in real-world scenarios and eager to see the outcomes of your crafted prompts!
            </li>
            
          </ul>
          
          <p><strong>Recap:</strong> Today, we&#39;ve explored iterative prompt refinement—tools and strategies to enhance prompt quality and achieve your goals. Remember, continuous iteration, testing, and adaptation will drive your prompt engineering success!</p>
          <p><strong>Call to action:</strong> Join the next module to master prompt applications in real-world scenarios!</p>
        </div>
        

        
        <div class="asset-block">
          <h3>Reading companion</h3>
          <p><strong>Summary:</strong> This handout focuses on iterative prompt refinement, teaching how to effectively refine prompts to achieve desired outcomes in data science and software development.</p>
          
          <h4>Sections</h4>
          <ul>
            
            <li>
              <strong>Iterative Refinement</strong>
              
              <ul>
                
                <li>Understand the concept of iterative refinement</li>
                
                <li>Identify strategies for effective prompt revision</li>
                
                <li>Realize the importance of feedback in the refinement process</li>
                
              </ul>
              
              <p>Iterative refinement involves repeatedly modifying prompts based on the results seen in practical applications. By analyzing outputs, individuals can make strategic adjustments to improve the clarity and effectiveness of prompts. This process is crucial to enhancing the alignment of prompts with intended outcomes.</p>
              
              <p class="muted">Outcomes: Apply iterative prompt refinement to achieve specific outcomes.</p>
              
            </li>
            
            <li>
              <strong>Testing Prompts</strong>
              
              <ul>
                
                <li>Develop techniques for prompt testing</li>
                
                <li>Learn to analyze prompt outputs</li>
                
                <li>Establish metrics for success</li>
                
              </ul>
              
              <p>Testing prompts is essential to understand their efficacy. Develop structured approaches to test various iterations of prompts in different scenarios. This includes quantitative metrics, such as response accuracy, and qualitative assessment, involving user feedback to gauge performance.</p>
              
              <p class="muted">Outcomes: Apply iterative prompt refinement to achieve specific outcomes.</p>
              
            </li>
            
            <li>
              <strong>Linking Prompts to Outcomes</strong>
              
              <ul>
                
                <li>Connect prompts directly to specific goals</li>
                
                <li>Define clear success criteria</li>
                
                <li>Track alignment of outcomes to prompt modifications</li>
                
              </ul>
              
              <p>To ensure prompts meet desired outcomes, it is important to link them directly to specific goals. Establish clear criteria for what success looks like and utilize tracking methods to monitor how modifications influence the outcomes. This helps refine prompts more efficiently based on their performance against these defined metrics.</p>
              
              <p class="muted">Outcomes: Apply iterative prompt refinement to achieve specific outcomes.</p>
              
            </li>
            
          </ul>
          
          
          <h4>Examples</h4>
          <ul>
            
            <li>
              <strong>Refining a Customer Service Query</strong> — A prompt is initially vague, resulting in suboptimal answers. By iteratively refining the question to specify customer context and required detail, the responses improve, fulfilling the original information need.
              
              <span class="muted">(Outcomes: Apply iterative prompt refinement to achieve specific outcomes.)</span>
              
            </li>
            
            <li>
              <strong>Improving Code Generation Prompts</strong> — A coding prompt generates generic code snippets. Through iterative testing and refinement, more context is added for specific coding requirements, significantly enhancing the usefulness of the output.
              
              <span class="muted">(Outcomes: Apply iterative prompt refinement to achieve specific outcomes.)</span>
              
            </li>
            
          </ul>
          
          
          <h4>Glossary</h4>
          <ul>
            
            <li><strong>Iterative Refinement</strong>: The process of gradually improving prompts based on repeated testing and feedback.</li>
            
            <li><strong>Prompt Testing</strong>: The methods used to evaluate the effectiveness of prompts in generating desired responses.</li>
            
            <li><strong>Outcome Alignment</strong>: The degree to which the prompts effectively achieve predefined goals.</li>
            
          </ul>
          
          
          <h4>Reflection prompts</h4>
          <ul>
            
            <li>Consider how iterative refinement can be applied in your daily work to achieve better results.</li>
            
            <li>Reflect on a time when a small change in a prompt led to significantly improved outcomes.</li>
            
            <li>Think about the metrics you can establish to measure the success of your prompt refinement efforts.</li>
            
          </ul>
          
        </div>
        

        
        <div class="asset-block">
          <h3>Quiz</h3>
          
          <form class="quiz-form" id="quiz-form-2">
            <ol>
              
              
              <li class="question" data-answer="B" data-stem="What is the primary goal of iterative prompt refinement in prompt engineering?">
                <div>
                  <strong>What is the primary goal of iterative prompt refinement in prompt engineering?</strong>
                  <span class="badge" aria-live="polite"></span>
                </div>
                <ul class="choice-list">
                  
                  <li>
                    <label>
                      <input type="radio" name="q0-m2" value="A" />
                      A. To create the most complex prompts possible.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q0-m2" value="B" />
                      B. To gradually improve prompts through testing and feedback.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q0-m2" value="C" />
                      C. To submit prompts without any adjustments.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q0-m2" value="D" />
                      D. To focus solely on the first draft of a prompt.
                    </label>
                  </li>
                  
                </ul>
                
                <p class="muted">Outcome: Apply iterative prompt refinement to achieve specific outcomes.</p>
                
                
                <p class="muted rationale" style="display:none;">Rationale: The primary goal of iterative prompt refinement is to improve prompts through repeated testing and feedback, allowing for adjustments that enhance outcomes.</p>
                
              </li>
              
              
              <li class="question" data-answer="B" data-stem="When testing a prompt, which of the following strategies is most effective to assess its performance?">
                <div>
                  <strong>When testing a prompt, which of the following strategies is most effective to assess its performance?</strong>
                  <span class="badge" aria-live="polite"></span>
                </div>
                <ul class="choice-list">
                  
                  <li>
                    <label>
                      <input type="radio" name="q1-m2" value="A" />
                      A. Change all variables at once to see which affects the outcome.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q1-m2" value="B" />
                      B. Test the prompt with different input variations one at a time.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q1-m2" value="C" />
                      C. Use the same input each time to ensure consistency.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q1-m2" value="D" />
                      D. Only focus on outputs from the first test.
                    </label>
                  </li>
                  
                </ul>
                
                <p class="muted">Outcome: Apply iterative prompt refinement to achieve specific outcomes.</p>
                
                
                <p class="muted rationale" style="display:none;">Rationale: Testing the prompt with different input variations one at a time allows for clear attribution of outcomes to specific changes, thereby facilitating effective refinement.</p>
                
              </li>
              
              
              <li class="question" data-answer="B" data-stem="Which of the following best illustrates a key step in linking a prompt to a specific desired outcome?">
                <div>
                  <strong>Which of the following best illustrates a key step in linking a prompt to a specific desired outcome?</strong>
                  <span class="badge" aria-live="polite"></span>
                </div>
                <ul class="choice-list">
                  
                  <li>
                    <label>
                      <input type="radio" name="q2-m2" value="A" />
                      A. Ignoring the context for simplicity.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q2-m2" value="B" />
                      B. Aligning the prompt&#39;s wording with the expected response.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q2-m2" value="C" />
                      C. Using jargon without explaining it.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q2-m2" value="D" />
                      D. Assuming all prompts will work in all contexts.
                    </label>
                  </li>
                  
                </ul>
                
                <p class="muted">Outcome: Link prompts to desired outcomes effectively.</p>
                
                
                <p class="muted rationale" style="display:none;">Rationale: Aligning the wording of the prompt with the expected response ensures that the prompt is directly related to the desired outcome, improving clarity and effectiveness.</p>
                
              </li>
              
              
              <li class="question" data-answer="B" data-stem="After refining a prompt that initially yielded irrelevant results, what would be an appropriate second step?">
                <div>
                  <strong>After refining a prompt that initially yielded irrelevant results, what would be an appropriate second step?</strong>
                  <span class="badge" aria-live="polite"></span>
                </div>
                <ul class="choice-list">
                  
                  <li>
                    <label>
                      <input type="radio" name="q3-m2" value="A" />
                      A. Launch the prompt without further adjustments.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q3-m2" value="B" />
                      B. Analyze the results of the prompt to identify weaknesses.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q3-m2" value="C" />
                      C. Assume the current prompt is perfect.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q3-m2" value="D" />
                      D. Discard the prompt without further analysis.
                    </label>
                  </li>
                  
                </ul>
                
                <p class="muted">Outcome: Apply iterative prompt refinement to achieve specific outcomes.</p>
                
                
                <p class="muted rationale" style="display:none;">Rationale: Analyzing the results helps to identify weaknesses and informs further adjustments, which is a critical component of the iterative process.</p>
                
              </li>
              
              
              <li class="question" data-answer="B" data-stem="How can feedback from testing help in the iterative refinement of a prompt?">
                <div>
                  <strong>How can feedback from testing help in the iterative refinement of a prompt?</strong>
                  <span class="badge" aria-live="polite"></span>
                </div>
                <ul class="choice-list">
                  
                  <li>
                    <label>
                      <input type="radio" name="q4-m2" value="A" />
                      A. It validates the prompt without the need for changes.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q4-m2" value="B" />
                      B. It informs adjustments needed to better align the prompt with the desired outcome.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q4-m2" value="C" />
                      C. Feedback is unnecessary if the prompt seems to work.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q4-m2" value="D" />
                      D. It complicates the prompt creation process.
                    </label>
                  </li>
                  
                </ul>
                
                <p class="muted">Outcome: Apply iterative prompt refinement to achieve specific outcomes.</p>
                
                
                <p class="muted rationale" style="display:none;">Rationale: Feedback from testing provides insights that guide necessary adjustments, ensuring that the prompt better aligns with desired outcomes as part of the iterative refinement process.</p>
                
              </li>
              
            </ol>
            <div class="quiz-actions">
              <button type="button" class="submit-quiz" data-module="2">Check answers</button>
            </div>
            <div class="quiz-result" id="quiz-result-2" aria-live="polite"></div>
          </form>
          
          
          <p><strong>Remediation tip:</strong> To reinforce the concepts of iterative prompt refinement, review the module summary and focus on the testing strategies discussed. Pay special attention to the importance of feedback in the iterative process and how refining prompts plays a crucial role in achieving desired results.</p>
          
        </div>
        
      </div>
      
      
      
      
      
      
      
      
      
      
      <div class="module">
        <h2>Module 3: Identifying Prompt Failures</h2>
        <p>Understand common pitfalls in prompting and strategies to address them.</p>
        <p><strong>Module outcomes:</strong> Identify and mitigate common prompt failures like hallucination and ambiguity.</p>
        <p><strong>Key topics:</strong> Common prompt failures, Hallucination in AI, Ambiguity in prompts</p>

        
        <div class="asset-block">
          <h3>Lesson Video</h3>
          <video controls preload="metadata">
            <source src="videos/the_fundamentals_of_prompt_engineering_module_3_identifying_prompt_failures_20251106193331.mp4" type="video/mp4" />
            
            <track kind="subtitles" src="videos/the_fundamentals_of_prompt_engineering_module_3_identifying_prompt_failures_20251106193331.vtt" srclang="en" label="English" default />
            
            
            <track kind="chapters" src="videos/the_fundamentals_of_prompt_engineering_module_3_identifying_prompt_failures_20251106193331.chapters.vtt" srclang="en" label="Chapters" />
            
            Your browser does not support the video tag.
          </video>
          <p class="muted">Narration voice: alloy</p>
        </div>
        

        
        <div class="asset-block">
          <h3>Video script</h3>
          <p><strong>Hook:</strong> Ever wondered why your prompts sometimes miss the mark? Let&#39;s dive in!</p>
          
          <h4>Outline</h4>
          <ul>
            
            <li>00:00 — Introduction to Prompt Failures</li>
            
            <li>01:00 — Common Types of Prompt Failures</li>
            
            <li>02:30 — Understanding Hallucination</li>
            
            <li>04:00 — Examples of Hallucination</li>
            
            <li>05:30 — What is Ambiguity?</li>
            
            <li>07:00 — Consequences of Ambiguous Prompts</li>
            
            <li>08:30 — Identifying Ambiguity in Your Prompts</li>
            
            <li>10:00 — Strategies for Mitigating Hallucination</li>
            
            <li>11:00 — Strategies for Reducing Ambiguity</li>
            
            <li>12:00 — Real-World Applications and Benefits</li>
            
            <li>13:30 — Recap of Key Takeaways</li>
            
            <li>14:00 — Conclusion and Next Steps</li>
            
          </ul>
          
          
          <h4>Narration</h4>
          <ul>
            
            <li>
              <strong>Introduction to Prompt Failures</strong>: Overview of prompt failures.<br />
              Welcome to Module 3, where we&#39;ll shine a light on prompt failures in AI.
Understanding these pitfalls is crucial for effective communication with AI.
Whether you&#39;re a budding data scientist or a software developer, these insights apply to you.
We&#39;ll cover common failures, like hallucination and ambiguity.
Ready to enhance your prompting skills? Let&#39;s get started!
            </li>
            
            <li>
              <strong>Common Types of Prompt Failures</strong>: Explore various prompt failures.<br />
              So, what exactly are prompt failures?
They can range from incorrect responses to unexpected outputs.
Common types include hallucination, ambiguity, and incomplete responses.
Identifying these failures helps us refine our approach.
By admitting these issues exist, we take the first step towards improvement.
            </li>
            
            <li>
              <strong>Understanding Hallucination</strong>: Define hallucination in AI responses.<br />
              Hallucination refers to when AI generates details that are incorrect.
For instance, asking a model about a historical event may yield fabricated facts.
This occurs due to biases in training data or poorly framed prompts.
Understanding the nature of hallucinations is key to mitigating them.
So, how can we identify when hallucinations happen?
            </li>
            
            <li>
              <strong>Examples of Hallucination</strong>: Review concrete examples to illustrate hallucination.<br />
              Let’s look at a specific case of hallucination.
Suppose you prompt the model about a recent event.
Instead of factual information, it invents a false narrative.
This can lead users astray, emphasizing the need for clarity. 
Have you encountered such discrepancies in your own prompts?
            </li>
            
            <li>
              <strong>What is Ambiguity?</strong>: Define ambiguity in the context of prompts.<br />
              Ambiguity arises when prompts can be interpreted in multiple ways.
Imagine asking, &#39;Tell me about Apple.&#39; Is it the fruit or the tech giant?
This confusion can lead to unpredictable or irrelevant responses.
Recognizing ambiguity sets the stage for crafting better prompts.
Can we avoid such pitfalls with careful wording?
            </li>
            
            <li>
              <strong>Consequences of Ambiguous Prompts</strong>: Discuss the negative outcomes of ambiguous prompts.<br />
              Ambiguity comes with consequences like wasted time and frustration.
Users may become discouraged or question the system&#39;s reliability.
Inconsistent answers reduce trust and effectiveness in AI applications.
By understanding these impacts, we can emphasize the importance of precision.
What might be the long-term effects of ambiguity in your prompts?
            </li>
            
            <li>
              <strong>Identifying Ambiguity in Your Prompts</strong>: Learn to detect ambiguity in prompt construction.<br />
              How can we spot ambiguity before it produces results?
Reread your prompts, looking for vague terms or dual meanings.
Consider testing with different phrasing to check results.
Seeking feedback from peers can help refine unclear prompts.
Are you ready to take this first step towards clarity?
            </li>
            
            <li>
              <strong>Strategies for Mitigating Hallucination</strong>: Explore methods to reduce hallucination occurrences.<br />
              To mitigate hallucination, start with fact-based prompts.
Grounding questions in known contexts leads to more accurate results.
For example, instead of open-ended questions, specify details.
Utilizing sources and examples builds a framework for data.
Would aligning prompts with reliable data sources improve outcomes?
            </li>
            
            <li>
              <strong>Strategies for Reducing Ambiguity</strong>: Discover techniques to clarify prompts.<br />
              Reducing ambiguity involves precise language and structure.
Break down complex prompts into simpler, direct questions.
Use context clues within prompts to guide the model’s understanding.
Testing iterations can reveal which wording produces the best clarity.
Are you prepared to refine your prompts for better results?
            </li>
            
            <li>
              <strong>Real-World Applications and Benefits</strong>: Connect theory to practical applications.<br />
              Let’s connect what we&#39;ve learned to real-world applications.
Proper prompting improves user experience and reliability in outputs.
For example, in customer support, clear prompts enhance resolution rates.
Greater accuracy fosters trust and encourages wider AI adoption.
How will these insights impact your future projects?
            </li>
            
            <li>
              <strong>Recap of Key Takeaways</strong>: Summarize the lessons on prompt failures.<br />
              We’ve covered critical insights on prompt failures and their implications.
Understanding hallucination and ambiguity forms the backbone of effective prompts.
Learning to identify these issues enables us to mitigate their effects.
Empowering ourselves with these strategies leads to more reliable outputs.
Which takeaways will you implement in your work?
            </li>
            
            <li>
              <strong>Conclusion and Next Steps</strong>: Encourage further action and learning.<br />
              As we wrap up, remember to put these insights into practice.
Assess your prompts critically and iterate continuously.
Engaging with communities and resources enhances your skills.
Thank you for joining Module 3, where every prompt counts.
What will your next prompt look like?
            </li>
            
          </ul>
          
          <p><strong>Recap:</strong> We&#39;ve explored identifying prompt failures, including hallucination and ambiguity.</p>
          <p><strong>Call to action:</strong> Now, apply these insights and craft clearer prompts in your projects!</p>
        </div>
        

        
        <div class="asset-block">
          <h3>Reading companion</h3>
          <p><strong>Summary:</strong> This module focuses on common pitfalls in prompting and strategies to overcome them, particularly hallucination and ambiguity.</p>
          
          <h4>Sections</h4>
          <ul>
            
            <li>
              <strong>Common Prompt Failures</strong>
              
              <ul>
                
                <li>Understand the types of prompt failures</li>
                
                <li>Recognize signs of hallucination</li>
                
                <li>Identify ambiguous prompts</li>
                
              </ul>
              
              <p>This section discusses typical mistakes made in designing prompts, highlighting common failures such as hallucinations where the model generates incorrect, fictitious responses, and ambiguities that lead to misunderstanding of user intent.</p>
              
              <p class="muted">Outcomes: Identify and mitigate common prompt failures like hallucination and ambiguity.</p>
              
            </li>
            
            <li>
              <strong>Hallucination in AI</strong>
              
              <ul>
                
                <li>Define hallucination in AI</li>
                
                <li>List the causes of hallucination</li>
                
                <li>Explore mitigation strategies</li>
                
              </ul>
              
              <p>Hallucination occurs when an AI model generates false or misleading information. Common causes include lack of context, overgeneralization, and insufficient training data. To mitigate this, it&#39;s important to test prompts and refine them based on the generated output.</p>
              
              <p class="muted">Outcomes: Identify and mitigate common prompt failures like hallucination.</p>
              
            </li>
            
            <li>
              <strong>Ambiguity in Prompts</strong>
              
              <ul>
                
                <li>Define prompt ambiguity</li>
                
                <li>Discuss the impact of ambiguity on outcomes</li>
                
                <li>Strategies to clarify prompts</li>
                
              </ul>
              
              <p>Ambiguous prompts can lead to unintended interpretations by AI models. Clarity can be achieved by using specific language, providing context, and asking direct questions. This reduces the likelihood of misunderstandings and improves response quality.</p>
              
              <p class="muted">Outcomes: Identify and mitigate common prompt failures like ambiguity.</p>
              
            </li>
            
          </ul>
          
          
          <h4>Examples</h4>
          <ul>
            
            <li>
              <strong>Example of Hallucination</strong> — A prompt asking for facts about a non-existent historical figure caused the model to invent details, showcasing hallucination.
              
              <span class="muted">(Outcomes: Identify and mitigate common prompt failures like hallucination.)</span>
              
            </li>
            
            <li>
              <strong>Example of Ambiguous Prompt</strong> — The prompt &#39;Tell me about the bank&#39; led to confusion between financial institutions and riverbanks, demonstrating the importance of specificity.
              
              <span class="muted">(Outcomes: Identify and mitigate common prompt failures like ambiguity.)</span>
              
            </li>
            
          </ul>
          
          
          <h4>Glossary</h4>
          <ul>
            
            <li><strong>Hallucination</strong>: When an AI model generates false or misleading information as a response.</li>
            
            <li><strong>Ambiguity</strong>: Uncertainty or inexactness in wording which can lead to multiple interpretations.</li>
            
          </ul>
          
          
          <h4>Reflection prompts</h4>
          <ul>
            
            <li>Reflect on previous experiences with prompts and identify instances of hallucination or ambiguity.</li>
            
            <li>Consider how to implement strategies discussed in this module in real scenarios.</li>
            
          </ul>
          
        </div>
        

        
        <div class="asset-block">
          <h3>Quiz</h3>
          
          <form class="quiz-form" id="quiz-form-3">
            <ol>
              
              
              <li class="question" data-answer="A" data-stem="Which of the following prompts is most likely to cause ambiguity in a response?">
                <div>
                  <strong>Which of the following prompts is most likely to cause ambiguity in a response?</strong>
                  <span class="badge" aria-live="polite"></span>
                </div>
                <ul class="choice-list">
                  
                  <li>
                    <label>
                      <input type="radio" name="q0-m3" value="A" />
                      A. What is the best programming language?
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q0-m3" value="B" />
                      B. Describe a time you faced a challenge.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q0-m3" value="C" />
                      C. What are the benefits of using AI?
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q0-m3" value="D" />
                      D. Can you explain quantum physics?
                    </label>
                  </li>
                  
                </ul>
                
                <p class="muted">Outcome: Identify common prompt failures such as ambiguity.</p>
                
                
                <p class="muted rationale" style="display:none;">Rationale: This prompt is ambiguous because it lacks specific criteria or context, making it unclear what is meant by &#39;best&#39;. It could lead to varied interpretations based on individual perspectives or needs.</p>
                
              </li>
              
              
              <li class="question" data-answer="B" data-stem="When creating a prompt, which of the following statements best describes &#39;hallucination&#39; in AI output?">
                <div>
                  <strong>When creating a prompt, which of the following statements best describes &#39;hallucination&#39; in AI output?</strong>
                  <span class="badge" aria-live="polite"></span>
                </div>
                <ul class="choice-list">
                  
                  <li>
                    <label>
                      <input type="radio" name="q1-m3" value="A" />
                      A. Output that accurately reflects a user&#39;s query.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q1-m3" value="B" />
                      B. The generation of information that appears relevant but is factually incorrect.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q1-m3" value="C" />
                      C. Responses that include the correct data and references.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q1-m3" value="D" />
                      D. A method of obtaining user feedback after responses.
                    </label>
                  </li>
                  
                </ul>
                
                <p class="muted">Outcome: Identify and mitigate common prompt failures like hallucination.</p>
                
                
                <p class="muted rationale" style="display:none;">Rationale: Hallucination refers to AI generating responses that seem plausible yet contain inaccuracies or fabrications. This issue is crucial to recognize to improve prompt engineering.</p>
                
              </li>
              
              
              <li class="question" data-answer="B" data-stem="Which strategy is most effective in minimizing ambiguity when crafting prompts?">
                <div>
                  <strong>Which strategy is most effective in minimizing ambiguity when crafting prompts?</strong>
                  <span class="badge" aria-live="polite"></span>
                </div>
                <ul class="choice-list">
                  
                  <li>
                    <label>
                      <input type="radio" name="q2-m3" value="A" />
                      A. Use general terms to avoid limiting the response.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q2-m3" value="B" />
                      B. Include specific criteria and examples in the prompt.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q2-m3" value="C" />
                      C. Ask open-ended questions to encourage creativity.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q2-m3" value="D" />
                      D. Avoid specifying the context of the inquiry.
                    </label>
                  </li>
                  
                </ul>
                
                <p class="muted">Outcome: Identify common prompt failures like ambiguity.</p>
                
                
                <p class="muted rationale" style="display:none;">Rationale: Including specific criteria and examples helps clarify expectations, reducing the likelihood of ambiguous responses and confusion in interpretation.</p>
                
              </li>
              
              
              <li class="question" data-answer="C" data-stem="You receive a response from an AI that includes a statistic you know to be incorrect. This response is an example of which problem?">
                <div>
                  <strong>You receive a response from an AI that includes a statistic you know to be incorrect. This response is an example of which problem?</strong>
                  <span class="badge" aria-live="polite"></span>
                </div>
                <ul class="choice-list">
                  
                  <li>
                    <label>
                      <input type="radio" name="q3-m3" value="A" />
                      A. Ambiguity
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q3-m3" value="B" />
                      B. Bias
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q3-m3" value="C" />
                      C. Hallucination
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q3-m3" value="D" />
                      D. Overfitting
                    </label>
                  </li>
                  
                </ul>
                
                <p class="muted">Outcome: Identify and mitigate common prompt failures like hallucination.</p>
                
                
                <p class="muted rationale" style="display:none;">Rationale: The AI producing a statistic that is incorrect is a clear manifestation of hallucination, where it generates content without factual basis despite appearing plausible.</p>
                
              </li>
              
              
              <li class="question" data-answer="C" data-stem="In a collaborative project using AI prompts, team members report varying interpretations of the same prompt. What is the primary issue present?">
                <div>
                  <strong>In a collaborative project using AI prompts, team members report varying interpretations of the same prompt. What is the primary issue present?</strong>
                  <span class="badge" aria-live="polite"></span>
                </div>
                <ul class="choice-list">
                  
                  <li>
                    <label>
                      <input type="radio" name="q4-m3" value="A" />
                      A. Too many prompts were used.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q4-m3" value="B" />
                      B. Lack of collaboration tools.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q4-m3" value="C" />
                      C. Ambiguity in the original prompt.
                    </label>
                  </li>
                  
                  <li>
                    <label>
                      <input type="radio" name="q4-m3" value="D" />
                      D. The AI was not trained properly.
                    </label>
                  </li>
                  
                </ul>
                
                <p class="muted">Outcome: Analyze common prompt failures and propose solutions.</p>
                
                
                <p class="muted rationale" style="display:none;">Rationale: The varying interpretations indicate that the original prompt likely contained ambiguity, leading to different understandings among team members of what was being asked.</p>
                
              </li>
              
            </ol>
            <div class="quiz-actions">
              <button type="button" class="submit-quiz" data-module="3">Check answers</button>
            </div>
            <div class="quiz-result" id="quiz-result-3" aria-live="polite"></div>
          </form>
          
          
          <p><strong>Remediation tip:</strong> Explore resources on creating effective AI prompts, focusing on clarity, specificity, and methods to identify and correct common failures.</p>
          
        </div>
        
      </div>
      
      

      <p class="muted">All materials are auto-generated drafts. Refine prompts and regenerate as needed.</p>
    </main>
    <script>
      (function () {
        function evaluateQuiz(form) {
          const questions = Array.from(form.querySelectorAll('.question'));
          let correct = 0;
          let wrong = 0;
          const wrongItems = [];
          questions.forEach((q, idx) => {
            q.classList.remove('correct', 'incorrect');
            const badge = q.querySelector('.badge');
            if (badge) { badge.textContent = ''; badge.classList.remove('correct','incorrect'); }
            const radios = q.querySelectorAll('input[type="radio"]');
            let selected = '';
            radios.forEach(r => { if (r.checked) selected = r.value; });
            const expected = (q.getAttribute('data-answer') || '').trim();
            const rationale = q.querySelector('.rationale');
            if (!selected) {
              wrong += 1;
              q.classList.add('incorrect');
              if (badge) { badge.textContent = 'Unanswered'; badge.classList.add('incorrect'); }
              if (rationale) rationale.style.display = '';
              wrongItems.push(q.getAttribute('data-stem') || ('Question ' + (idx+1)));
            } else if (selected.toUpperCase() === expected.toUpperCase()) {
              correct += 1;
              q.classList.add('correct');
              if (badge) { badge.textContent = 'Correct'; badge.classList.add('correct'); }
              if (rationale) rationale.style.display = 'none';
            } else {
              wrong += 1;
              q.classList.add('incorrect');
              if (badge) { badge.textContent = 'Incorrect'; badge.classList.add('incorrect'); }
              if (rationale) rationale.style.display = '';
              wrongItems.push(q.getAttribute('data-stem') || ('Question ' + (idx+1)));
            }
          });
          const total = questions.length || 1;
          const percent = Math.round((correct / total) * 100);
          const res = form.querySelector('.quiz-result');
          if (res) {
            res.innerHTML = '' +
              '<div class="stats">Score: ' + correct + '/' + total + ' (' + percent + '%)</div>' +
              '<div>Wrong: ' + wrong + '</div>' +
              (wrongItems.length ? '<div class="wrong-list"><strong>Review:</strong> ' + wrongItems.map(x => x).join('; ') + '</div>' : '');
          }
        }

        document.addEventListener('click', function (e) {
          const btn = e.target.closest('.submit-quiz');
          if (!btn) return;
          const mod = btn.getAttribute('data-module');
          const form = document.getElementById('quiz-form-' + mod);
          if (form) evaluateQuiz(form);
        });
      })();
    </script>
  </body>
  </html>